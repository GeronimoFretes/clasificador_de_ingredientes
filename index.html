<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Demo – Clasificador de Ingredientes</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <style>
    body {
      font-family: system-ui, Arial, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 1rem;
      padding: 2rem;
      background: #f7f7f7;
    }
    video {
      border-radius: 1rem;
      box-shadow: 0 4px 16px rgba(0,0,0,.15);
    }
    #pred {
      font-size: 1.5rem;
      font-weight: 600;
      padding: .5rem 1rem;
      border-radius: .75rem;
      background: #fff;
      box-shadow: 0 2px 8px rgba(0,0,0,.1);
    }
    #status {
      font-size: .9rem;
      color: #666;
    }
  </style>
</head>
<body>
  <h1>Clasificador de Ingredientes</h1>
  <video id="webcam" width="300" height="225" autoplay muted playsinline></video>
  <canvas id="hidden" width="224" height="224" style="display:none"></canvas>
  <div id="pred">Cargando modelo…</div>
  <div id="status"></div>

<script>
(async () => {
  // ------- config -------
  const MODEL_PATH = 'models/best_model.onnx';
  const INPUT_NAME = 'input';
  const MEAN = [0.485, 0.456, 0.406];
  const STD  = [0.229, 0.224, 0.225];
  const CLASS_NAMES = [
    'manteca',
    'banana',
    'harina',
    'leche',
    'huevo',
    'azucar'
  ];

  // helper: convert ImageData -> Float32 NCHW tensor
  function preprocess(imgData){
    const {data, width, height} = imgData;
    const float32 = new Float32Array(3 * width * height);
    let px = 0;
    for (let y = 0; y < height; y++) {
      for (let x = 0; x < width; x++) {
        const idx = (y * width + x) * 4;
        const r = data[idx]   / 255;
        const g = data[idx+1] / 255;
        const b = data[idx+2] / 255;
        float32[px]                          = (r - MEAN[0]) / STD[0];
        float32[px +   width * height]      = (g - MEAN[1]) / STD[1];
        float32[px + 2 * width * height]    = (b - MEAN[2]) / STD[2];
        px++;
      }
    }
    return float32;
  }

  // init webcam
  const video = document.getElementById('webcam');
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'environment' }
    });
    video.srcObject = stream;
  } catch (err) {
    document.getElementById('pred').textContent = '⚠️ Webcam access denied.';
    console.error(err);
    return;
  }

  // load ONNX model
  const session = await ort.InferenceSession.create(MODEL_PATH, {
    executionProviders: ['wasm']
  });
  document.getElementById('pred').textContent = 'Model loaded – warming up…';

  const canvas = document.getElementById('hidden');
  const ctx = canvas.getContext('2d');

  async function infer() {
    if (video.readyState >= 2) {
      ctx.drawImage(video, 0, 0, 224, 224);
      const imgData = ctx.getImageData(0, 0, 224, 224);
      const inputData = preprocess(imgData);
      const tensor = new ort.Tensor('float32', inputData, [1, 3, 224, 224]);
      const output = await session.run({ [INPUT_NAME]: tensor });
      const logits = output[session.outputNames[0]].data;
      // argmax
      let maxIdx = 0, maxVal = logits[0];
      for (let i = 1; i < logits.length; i++) {
        if (logits[i] > maxVal) {
          maxVal = logits[i];
          maxIdx = i;
        }
      }
      // softmax probability
      const exps = logits.map(v => Math.exp(v - maxVal));
      const sum = exps.reduce((a, b) => a + b, 0);
      const prob = exps[maxIdx] / sum;
      const label = CLASS_NAMES[maxIdx] || `class_${maxIdx}`;
      document.getElementById('pred').textContent = `${label} ${(prob * 100).toFixed(1)}%`;
    }
    requestAnimationFrame(infer);
  }

  infer();
})();
</script>
</body>
</html>
